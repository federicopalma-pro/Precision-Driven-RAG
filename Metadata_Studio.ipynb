{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfddecb-37b9-45e2-9eb4-c74dd0984560",
   "metadata": {},
   "source": [
    "### System libraries & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68031f5-ac47-4545-808a-d5ed02d496a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import os\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c198e1a3-1c92-4900-87f3-7c6cdf7ce7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab290af-35df-4ef2-92f0-ebb6e8b38c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beb35082-89fc-4d0f-9bee-cb35de9aedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_openai = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7add02af-ec68-4b5e-92bd-20e5288e9735",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"./semantic_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1698f4-e413-4658-84a1-9846b04b442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_chunks = client.get_collection(\"docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0667df5a-bc9c-42ea-b95d-658a4ef2e4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection_chunks.get()['ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb147581-ddb0-4858-91ca-ae17493269b9",
   "metadata": {},
   "source": [
    "### Matadata builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfdc81f7-8583-4ba1-80ca-06b15aade0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = collection_chunks.get()['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e2656c-0395-43db-b18f-d69042c1b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = collection_chunks.get()['ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebe92d5e-cb04-40ff-ba71-92635d90a9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02077054-496d-4b39-935b-7fa950ba2b13'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e61ab6-a748-4710-83ac-5f72c023642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_document = {\n",
    "                  \"source\": \"alice_in_wonderland.txt\",\n",
    "                  \"title\": \"Alice's Adventures in Wonderland\",\n",
    "                  \"author\": \"Lewis Carroll\",\n",
    "                  \"edition\": \"The Millennium Fulcrum Edition 3.0\",\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afae6b01-9dd1-47cd-88e5-ecc0d3f8e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_chunk = {\n",
    "                \"chapter\": \"\",\n",
    "                \"chapter_title\": \"\",\n",
    "                \"characters\": [],\n",
    "                \"key_events\": [],\n",
    "                \"themes\": [],\n",
    "                \"setting\": \"\",\n",
    "                \"quotes\": [],\n",
    "                \"narrative_style\": \"\",\n",
    "                \"summary\": \"\",\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acdcc8f2-2132-42c1-84ce-956ecfff659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = f\"\"\"\n",
    "Follow these instructions carefully:\n",
    "\n",
    "1. Read and analyze the content of the CHUNK: {chunk}.   \n",
    "   Pay attention to key information, facts, dates, names, and any other relevant details.\n",
    "\n",
    "2. Accurately extract relevant information to add to the metadata {metadata_document}, using the specific details from the {metadata_chunk}.\n",
    "\n",
    "3. For each field in the metadata_document, ensure that they remain unchanged.\n",
    "\n",
    "4. For each field in metadata_chunk structures, extract the corresponding information from the CHUNK.\n",
    "   Ensure that the information you extract is accurate and directly related to the field.\n",
    "\n",
    "5. Fill in the metadata fields with the extracted information.\n",
    "   Be precise and concise in your entries.\n",
    "   If a particular field cannot be filled based on the information in the CHUNK, leave it empty (do not use null, undefined, or any placeholder values).\n",
    "\n",
    "6. Pay special attention to the data types of the metadata fields:\n",
    "   - Use strings (str) for text-based information\n",
    "   - Use integers (int) for whole numbers\n",
    "   - Use floats (float) for decimal numbers\n",
    "   - Use booleans (bool) for true/false values\n",
    "\n",
    "7. Do not use lists or nested structures in your output.\n",
    "   When listing items, use a string format with items separated by commas.\n",
    "   For example, instead of using a list structure like ['Federico', 'Marco', 'Luigi'], write \"Federico, Marco, Luigi\"\n",
    "\n",
    "8. Ensure that your final output is a valid JSON string that can be correctly parsed using json.loads().\n",
    "   The output should be a single dictionary containing all the filled metadata fields.\n",
    "\n",
    "9. Here's an example of how your output should be structured:\n",
    "\n",
    "   {{\n",
    "     \"title\": \"Sample Article Title\",\n",
    "     \"author\": \"John Doe, Federico Palma\",\n",
    "     \"publication_date\": \"2023-05-15\",\n",
    "     \"word_count\": 500,\n",
    "     \"is_peer_reviewed\": true,\n",
    "     \"average_rating\": 4.5\n",
    "   }}\n",
    "\n",
    "10. Remember to maintain the integrity and accuracy of the metadata. Double-check your entries to ensure they correctly represent the information in the CHUNK.\n",
    "\n",
    "11. If you're unsure about a particular field or if the information is not explicitly stated in the CHUNK, use your best judgment based on the context.\n",
    "    However, avoid making unfounded assumptions.\n",
    "\n",
    "12. After completing the analysis and extraction, review your output to ensure all fields are correctly filled and the format is valid JSON.\n",
    "\n",
    "Provide your final output as a JSON string that combines metadata_document and metadata_chunk.\n",
    "Do not include any explanations or additional text outside of the JSON string.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0b26ed1-ffb8-48c8-a334-f35f80bd837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"\"\"You are tasked with analyzing a given text chunk and extracting relevant information to populate metadata fields.\"\"\"),\n",
    "    (\"human\", prompt_template),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a2cb67b-f165-4f01-972c-4013198e9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm_openai.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc0bc165-e488-4669-8649-bc7f3679ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = answer.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75d627b1-5150-46f1-9c61-5b32c1d7beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Converte la stringa pulita in un dizionario\n",
    "    metadata_json = json.loads(metadata)\n",
    "except json.JSONDecodeError as e:\n",
    "        print(f\"JSON error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7226cbd5-093b-4545-a428-14618e53b9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'alice_in_wonderland.txt',\n",
       " 'title': \"Alice's Adventures in Wonderland\",\n",
       " 'author': 'Lewis Carroll',\n",
       " 'edition': 'The Millennium Fulcrum Edition 3.0',\n",
       " 'chapter': 'XI',\n",
       " 'chapter_title': 'Who Stole the Tarts?',\n",
       " 'characters': \"Alice, Gryphon, Mock Turtle, King of Hearts, Queen of Hearts, Knave of Hearts, White Rabbit, Hatter, March Hare, Dormouse, Bill the Lizard, Duchess's Cook\",\n",
       " 'key_events': \"The trial begins, The Hatter gives evidence, Alice grows larger, The Queen orders the Hatter's execution, The Duchess's Cook is called as a witness\",\n",
       " 'themes': 'Justice, Absurdity, Growth',\n",
       " 'setting': 'Court of the King and Queen of Hearts',\n",
       " 'quotes': \"'The Queen of Hearts, she made some tarts, All on a summer day: The Knave of Hearts, he stole those tarts, And took them quite away!', 'Consider your verdict,' the King said to the jury.\",\n",
       " 'narrative_style': 'Third-person',\n",
       " 'summary': \"The trial of the Knave of Hearts begins, with various characters giving evidence. Alice grows larger during the trial, causing some commotion. The Queen orders the Hatter's execution, but he escapes. The Duchess's Cook is called as the next witness.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560c341-65c5-4a29-b386-eb907bafb80b",
   "metadata": {},
   "source": [
    "### Update metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20d65753-39ec-4482-a513-d575fb946ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_json['chapter'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a30d0b6a-404e-41a9-bac8-938b5184841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_json['chapter_title'] = \"A Mad Tea-Party.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2ce754b-b99f-4cca-a49e-522a82cdfd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection_chunks.update(ids=[doc_id], metadatas=metadata_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff36af-71b7-4d2c-9457-325b8c827e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
